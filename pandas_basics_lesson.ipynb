{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Basics: Customer Purchasing Behavior Analysis\n",
    "\n",
    "In this tutorial, we will explore the fundamental operations and functionalities of the Pandas library using a dataset on customer purchasing behavior. \n",
    "\n",
    "By the end of this lesson, you will learn how to:\n",
    "- load data into a DataFrame\n",
    "- perform basic data exploration\n",
    "- select and filter data\n",
    "- execute basic data operations\n",
    "\n",
    "\n",
    "This hands-on approach will help you gain practical skills in data manipulation and analysis with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a DataFrame?\n",
    "\n",
    "A Pandas DataFrame is a two-dimensional table with labeled rows and columns that can hold different types of data and can be resized. It is similar to a table in a database, an Excel spreadsheet. Each column in a DataFrame can contain different data types (e.g., integers, floats, strings), and the DataFrame provides a variety of methods for data manipulation, analysis, and visualization.\n",
    "\n",
    "Key features of a DataFrame include:\n",
    "- **Labeled axes**: Both rows and columns have labels, which makes it easy to access and manipulate data.\n",
    "- **Heterogeneous data**: Different columns can contain different types of data.\n",
    "- **Size-mutable**: You can add or remove columns and rows.\n",
    "- **Integrated operations**: Built-in methods for data manipulation, such as filtering, grouping, and aggregation.\n",
    "\n",
    "For more details, you can refer to the [Pandas documentation on DataFrames](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, make sure you have the **Pandas** library installed. **Pandas** is a powerful data manipulation and analysis library for Python.\n",
    "\n",
    "After you have installed your virtual environment, `venv`, install the Pandas library using `pip`:\n",
    "\n",
    "```bash\n",
    "pip install pandas \n",
    "```\n",
    "\n",
    "\n",
    "After you have installed the library, run the block below to import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create all of our functions, study them, and then invoke them.\n",
    "Our functions will be:\n",
    "\n",
    "- load_data() - loads the data from the CSV file into a DataFrame\n",
    "- explore_dataframe(df) - explores the DataFrame\n",
    "- data_selection(df) - selects and filters the data from the DataFrame\n",
    "- data_operations(df) - performs basic data operations on the DataFrame\n",
    "\n",
    "**Note:** Try to read and interpret the code for each function `before` you read the explanation.\n",
    "\n",
    "Before you start, let's take a look at the [data](./data/customer_data.csv) we will be working with in the `load_data()` function.\n",
    "\n",
    "**[Customer Data CSV LINK](./data/customer_data.csv)**\n",
    "\n",
    "Let's start with the `load_data()` function. What is it doing? After you have discussed the code, run the code block below to create the function. Again, you will only see a checkmark, however the function declaration will be stored in the `pandas_basics_lesson.ipynb` file for later invocations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('data/customer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Explanation: `load_data()`\n",
    "\n",
    "The `load_data()` function reads a CSV file named `customer_data.csv` from the `data` directory and loads it into a Pandas DataFrame. This DataFrame will contain all the customer data from the CSV file, making it ready for further analysis and manipulation using Pandas.\n",
    "\n",
    "Let's create the `explore_dataframe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataframe(df):\n",
    "    \"\"\"Demonstrate basic DataFrame operations.\"\"\"\n",
    "    print(\"First 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Explanation: `explore_dataframe(df)`\n",
    "\n",
    "The `explore_dataframe(df)` function demonstrates basic DataFrame operations using the following methods:\n",
    "\n",
    "- `df.head()`: This method returns the first 5 rows of the DataFrame by default. You can specify a different number of rows by passing an argument, e.g., `df.head(10)` to return the first 10 rows. It is useful for quickly inspecting the initial entries of the dataset.\n",
    "\n",
    "- `df.info()`: Provides a concise summary of the DataFrame, including the index dtype and column dtypes, non-null values, and memory usage.\n",
    "\n",
    "- `df.describe()`: Generates descriptive summary statistics for numerical columns, such as count, mean (average), std (standard deviation), min, 25%, 50%, 75%, and max.\n",
    "\n",
    "These methods help in understanding the structure and properties of the DataFrame, making it easier to perform subsequent data analysis tasks.\n",
    "\n",
    "Let's create the `data_selection(df)` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview: Selecting Columns from a DataFrame\n",
    "\n",
    "Selecting specific columns from a DataFrame is a common operation in data analysis. It allows you to focus on the relevant parts of your dataset, making it easier to perform analysis, visualization, and reporting. By selecting only the necessary columns, you can reduce memory usage and improve the performance of your data processing tasks. Additionally, selecting columns can help in cleaning and preparing data by isolating the features of interest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(df):\n",
    "    \"\"\"Demonstrate data selection and indexing.\"\"\"\n",
    "    print(\"Selecting 'age' and 'annual_income' columns:\")\n",
    "    print(df[['age', 'annual_income']].head())\n",
    "    \n",
    "    print(\"\\nFiltering customers with loyalty_score > 75:\")\n",
    "    print(df[df['loyalty_score'] > 75].head())\n",
    "    \n",
    "    print(\"\\nUsing loc to select specific rows and columns:\")\n",
    "    print(df.loc[0:4, ['user_id', 'age', 'purchase_amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Explanation: `data_selection(df)`\n",
    "\n",
    "The `data_selection(df)` function demonstrates various techniques for selecting and filtering data within a DataFrame. Here is a breakdown of what each part of the function does:\n",
    "\n",
    "- `df[['age', 'annual_income']]`: This line selects the 'age' and 'annual_income' columns from the DataFrame and returns a new DataFrame containing only these columns. The `head()` method is then used to display the first 5 rows of this new DataFrame.\n",
    "\n",
    "- `df[df['loyalty_score'] > 75]`: This line filters the DataFrame to include only the rows where the 'loyalty_score' column value is greater than 75. The `head()` method is used again to display the first 5 rows of this filtered DataFrame.\n",
    "\n",
    "- `df.loc[0:4, ['user_id', 'age', 'purchase_amount']]`: This line uses the `loc` indexer to select rows 0 to 4, inclusive, and the specified columns from the DataFrame. The `loc` indexer allows for both row and column selection using labels. The `head()` method is used to display the first 5 rows of this selected DataFrame.\n",
    "\n",
    "How does `loc` work? Do some research on the internet, in the documentation or using AI.\n",
    "\n",
    "These examples showcase how to select specific columns, filter rows based on conditions, and use label-based indexing to extract desired subsets of data from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_operations(df):\n",
    "    \"\"\"Demonstrate basic data operations.\"\"\"\n",
    "    df['average_purchase'] = df['purchase_amount'] / df['purchase_frequency']\n",
    "    print(\"Added 'average_purchase' column:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nSorting by purchase_amount (descending):\")\n",
    "    print(df.sort_values('purchase_amount', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Explanation: `data_operations(df)`\n",
    "\n",
    "The `data_operations(df)` function demonstrates basic data operations on a DataFrame. Here is a breakdown of what each part of the function does:\n",
    "\n",
    "- `df['average_purchase'] = df['purchase_amount'] / df['purchase_frequency']`: This line creates a new column named 'average_purchase' in the DataFrame. The values in this new column are calculated by dividing the 'purchase_amount' column by the 'purchase_frequency' column.\n",
    "\n",
    "- `df.sort_values('purchase_amount', ascending=False)`: This line sorts the DataFrame by the 'purchase_amount' column in descending order. The `head()` method is used to display the first 5 rows of the sorted DataFrame.\n",
    "\n",
    "These operations help in performing calculations, sorting data, and adding new columns to a DataFrame, which are fundamental tasks in data analysis and manipulation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to invoke the functions we've created. First, let's invoke the `load_data()` function and set it to a variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's invoke the `explore_dataframe()` function with `df` as the argument. Be sure to study the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Exploring DataFrame\n",
      "First 5 rows:\n",
      "   user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
      "0        1   25          45000              200            4.5  North   \n",
      "1        2   34          55000              350            7.0  South   \n",
      "2        3   45          65000              500            8.0   West   \n",
      "3        4   22          30000              150            3.0   East   \n",
      "4        5   29          47000              220            4.8  North   \n",
      "\n",
      "   purchase_frequency  \n",
      "0                  12  \n",
      "1                  18  \n",
      "2                  22  \n",
      "3                  10  \n",
      "4                  13  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238 entries, 0 to 237\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             238 non-null    int64  \n",
      " 1   age                 238 non-null    int64  \n",
      " 2   annual_income       238 non-null    int64  \n",
      " 3   purchase_amount     238 non-null    int64  \n",
      " 4   loyalty_score       238 non-null    float64\n",
      " 5   region              238 non-null    object \n",
      " 6   purchase_frequency  238 non-null    int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 13.1+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "          user_id         age  annual_income  purchase_amount  loyalty_score  \\\n",
      "count  238.000000  238.000000     238.000000       238.000000     238.000000   \n",
      "mean   119.500000   38.676471   57407.563025       425.630252       6.794118   \n",
      "std     68.848868    9.351118   11403.875717       140.052062       1.899047   \n",
      "min      1.000000   22.000000   30000.000000       150.000000       3.000000   \n",
      "25%     60.250000   31.000000   50000.000000       320.000000       5.500000   \n",
      "50%    119.500000   39.000000   59000.000000       440.000000       7.000000   \n",
      "75%    178.750000   46.750000   66750.000000       527.500000       8.275000   \n",
      "max    238.000000   55.000000   75000.000000       640.000000       9.500000   \n",
      "\n",
      "       purchase_frequency  \n",
      "count          238.000000  \n",
      "mean            19.798319  \n",
      "std              4.562884  \n",
      "min             10.000000  \n",
      "25%             17.000000  \n",
      "50%             20.000000  \n",
      "75%             23.000000  \n",
      "max             28.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Exploring DataFrame\")\n",
    "explore_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's invoke the `data_selection()` function with `df` as the argument. Take a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Data Selection and Indexing\n",
      "Selecting 'age' and 'annual_income' columns:\n",
      "   age  annual_income\n",
      "0   25          45000\n",
      "1   34          55000\n",
      "2   45          65000\n",
      "3   22          30000\n",
      "4   29          47000\n",
      "\n",
      "Filtering customers with loyalty_score > 75:\n",
      "Empty DataFrame\n",
      "Columns: [user_id, age, annual_income, purchase_amount, loyalty_score, region, purchase_frequency]\n",
      "Index: []\n",
      "\n",
      "Using loc to select specific rows and columns:\n",
      "   user_id  age  purchase_amount\n",
      "0        1   25              200\n",
      "1        2   34              350\n",
      "2        3   45              500\n",
      "3        4   22              150\n",
      "4        5   29              220\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Data Selection and Indexing\")\n",
    "data_selection(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's invoke the `data_operations()` function with `df` as the argument. Take a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Basic Data Operations\n",
      "Added 'average_purchase' column:\n",
      "   user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
      "0        1   25          45000              200            4.5  North   \n",
      "1        2   34          55000              350            7.0  South   \n",
      "2        3   45          65000              500            8.0   West   \n",
      "3        4   22          30000              150            3.0   East   \n",
      "4        5   29          47000              220            4.8  North   \n",
      "\n",
      "   purchase_frequency  average_purchase  \n",
      "0                  12         16.666667  \n",
      "1                  18         19.444444  \n",
      "2                  22         22.727273  \n",
      "3                  10         15.000000  \n",
      "4                  13         16.923077  \n",
      "\n",
      "Sorting by purchase_amount (descending):\n",
      "     user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
      "119      120   55          75000              640            9.5   West   \n",
      "179      180   55          75000              640            9.5   West   \n",
      "59        60   55          75000              640            9.5   West   \n",
      "149      150   55          75000              640            9.5   West   \n",
      "209      210   55          75000              640            9.5   West   \n",
      "\n",
      "     purchase_frequency  average_purchase  \n",
      "119                  28         22.857143  \n",
      "179                  28         22.857143  \n",
      "59                   28         22.857143  \n",
      "149                  28         22.857143  \n",
      "209                  28         22.857143  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Basic Data Operations\")\n",
    "data_operations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You have successfully completed the Pandas Basics tutorial. Now it's time to test your skills and apply your knowledge with a challenge. Navigate to the [Employee Performance Challenge](./employee_performance_challenge.md) file and follow the instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
